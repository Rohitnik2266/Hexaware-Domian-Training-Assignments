{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K68mKQLsiinu"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta import configure_spark_with_delta_pip\n",
        "from pyspark.sql.functions import col, when, sum as _sum\n",
        "\n",
        "builder = SparkSession.builder \\\n",
        "    .appName(\"ECommercePipeline\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DgXb_Qz5ipKb"
      },
      "outputs": [],
      "source": [
        "\n",
        "orders_path = \"orders_delta\"\n",
        "customers_path = \"customers_delta\"\n",
        "products_path = \"products_delta\"\n",
        "\n",
        "\n",
        "orders_df = spark.read.csv(\"orders.csv\", header=True, inferSchema=True)\n",
        "orders_df.write.format(\"delta\").mode(\"overwrite\").save(orders_path)\n",
        "customers_df = spark.read.csv(\"customers.csv\", header=True, inferSchema=True)\n",
        "customers_df.write.format(\"delta\").mode(\"overwrite\").save(customers_path)\n",
        "\n",
        "products_df = spark.read.csv(\"products.csv\", header=True, inferSchema=True)\n",
        "products_df.write.format(\"delta\").mode(\"overwrite\").save(products_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnXNwDpCi7HV",
        "outputId": "eb5766c9-ecad-4d9c-fb0a-7046eab98a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+------------+\n",
            "|ProductID|TotalRevenue|\n",
            "+---------+------------+\n",
            "|    P1001|       75000|\n",
            "|    P1002|       50000|\n",
            "|    P1003|       30000|\n",
            "+---------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "orders_df = spark.read.format(\"delta\").load(orders_path)\n",
        "\n",
        "\n",
        "orders_df.createOrReplaceTempView(\"orders\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT ProductID, SUM(Quantity * Price) AS TotalRevenue\n",
        "    FROM orders\n",
        "    WHERE Status = 'Delivered'\n",
        "    GROUP BY ProductID\n",
        "\"\"\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL5n-XQWi7KM",
        "outputId": "ae25196e-04ec-4f31-f2af-f81cb1f58cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------------+\n",
            "|Region|RegionRevenue|\n",
            "+------+-------------+\n",
            "|  West|        30000|\n",
            "| North|       125000|\n",
            "+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "customers = spark.read.format(\"delta\").load(customers_path)\n",
        "orders = spark.read.format(\"delta\").load(orders_path)\n",
        "\n",
        "orders.join(customers, \"CustomerID\") \\\n",
        "    .filter(col(\"Status\") == \"Delivered\") \\\n",
        "    .groupBy(\"Region\") \\\n",
        "    .agg(_sum(col(\"Quantity\") * col(\"Price\")).alias(\"RegionRevenue\")) \\\n",
        "    .show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DxYTp8fAlJHD"
      },
      "outputs": [],
      "source": [
        "from delta.tables import DeltaTable\n",
        "\n",
        "delta_orders = DeltaTable.forPath(spark, orders_path)\n",
        "\n",
        "delta_orders.update(\n",
        "    condition=col(\"Status\") == \"Pending\",\n",
        "    set={\"Status\": \"'Cancelled'\"}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ag_wGNb6lJJ7"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "new_return = spark.createDataFrame([\n",
        "    Row(OrderID=3006, CustomerID='C003', ProductID='P1003', Quantity=1, Price=30000, OrderDate='2024-05-06', Status='Returned')\n",
        "])\n",
        "\n",
        "delta_orders.alias(\"target\").merge(\n",
        "    new_return.alias(\"source\"),\n",
        "    \"target.OrderID = source.OrderID\"\n",
        ").whenNotMatchedInsertAll().execute()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DO2WE3XMlJMz"
      },
      "outputs": [],
      "source": [
        "cleaned_orders = spark.read.format(\"delta\").load(orders_path).dropna()\n",
        "cleaned_orders.write.format(\"delta\").mode(\"overwrite\").save(\"cleaned_orders_delta\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl7O37_0lTbu",
        "outputId": "ba6c9611-148f-4ad5-c32b-51ba7c46dff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+------------+\n",
            "|   Category|TotalRevenue|\n",
            "+-----------+------------+\n",
            "|Electronics|      285000|\n",
            "|Accessories|       30000|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "products = spark.read.format(\"delta\").load(products_path)\n",
        "cleaned_orders = spark.read.format(\"delta\").load(\"cleaned_orders_delta\")\n",
        "\n",
        "cleaned_orders.join(products, \"ProductID\") \\\n",
        "    .withColumn(\"Revenue\", col(\"Quantity\") * col(\"Price\")) \\\n",
        "    .groupBy(\"Category\") \\\n",
        "    .agg(_sum(\"Revenue\").alias(\"TotalRevenue\")) \\\n",
        "    .show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD_qcEVulTL2",
        "outputId": "df42480c-66d3-4624-9b86-cc71397f2996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+---------+--------+-----+----------+---------+\n",
            "|OrderID|CustomerID|ProductID|Quantity|Price| OrderDate|   Status|\n",
            "+-------+----------+---------+--------+-----+----------+---------+\n",
            "|   3001|      C001|    P1001|       1|75000|2024-05-01|Delivered|\n",
            "|   3002|      C002|    P1002|       2|50000|2024-05-02| Returned|\n",
            "|   3003|      C003|    P1003|       1|30000|2024-05-03|Delivered|\n",
            "|   3004|      C001|    P1002|       1|50000|2024-05-04|Delivered|\n",
            "|   3005|      C004|    P1004|       3|10000|2024-05-05|  Pending|\n",
            "+-------+----------+---------+--------+-----+----------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(orders_path).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LbfYxcFRl1up"
      },
      "outputs": [],
      "source": [
        "old_df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(orders_path)\n",
        "old_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(orders_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAt1Pn9Zl6Ia",
        "outputId": "d39d5544-e7bf-45eb-8de4-11fd391887e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"false\")\n",
        "delta_orders.vacuum(retentionHours=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmn1dK0tl58L",
        "outputId": "08f14fa7-a65b-4203-9ad5-d3299a416168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+---------+--------+-----+---------+------+\n",
            "|OrderID|CustomerID|ProductID|Quantity|Price|OrderDate|Status|\n",
            "+-------+----------+---------+--------+-----+---------+------+\n",
            "+-------+----------+---------+--------+-----+---------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "orders = spark.read.format(\"delta\").load(orders_path)\n",
        "\n",
        "orders.filter(\n",
        "    (col(\"Quantity\") <= 0) |\n",
        "    (col(\"Price\") <= 0) |\n",
        "    (col(\"OrderDate\").isNull())\n",
        ").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOvRp9hkmoC9",
        "outputId": "149faa79-0220-4dbe-c46e-2cc4c5301c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---------+---------+\n",
            "|OrderID|   Status|OrderType|\n",
            "+-------+---------+---------+\n",
            "|   3001|Delivered|   Normal|\n",
            "|   3002| Returned|   Return|\n",
            "|   3003|Delivered|   Normal|\n",
            "|   3004|Delivered|   Normal|\n",
            "|   3005|  Pending|   Normal|\n",
            "+-------+---------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "orders.withColumn(\n",
        "    \"OrderType\",\n",
        "    when(col(\"Status\") == \"Returned\", \"Return\").otherwise(\"Normal\")\n",
        ").select(\"OrderID\", \"Status\", \"OrderType\").show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
